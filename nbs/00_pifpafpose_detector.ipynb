{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pifpafpose_detector\n",
    "\n",
    "> Pose Detector class based on Open PifPaf and some pose modification tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pifpafpose_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# These torch versions are entirely out of date, unfortunately\n",
    "#%pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#%pip install openpifpaf #==0.12.14\n",
    "#OpenPifPaf still tries to read PIL.PILLOW_VERSION instead of PIL.__version__ (which has been changed for a while)\n",
    "#%pip install --force-reinstall \"Pillow<9.0\" --no-deps\n",
    "#%pip install opencv-python\n",
    "\n",
    "#!wget https://github.com/vita-epfl/openpifpaf-torchhub/releases/download/v0.11.0/shufflenetv2k30w-200510-104256-cif-caf-caf25-o10s-0b5ba06f.pkl\n",
    "#!wget https://github.com/DuncanZauss/openpifpaf_assets/releases/download/v0.1.0/center_ref_shufflenetv2k30.pkl.epoch350\n",
    "#!wget http://github.com/DuncanZauss/openpifpaf_assets/releases/download/v0.1.0/sk16_wholebody.pkl\n",
    "#!wget http://github.com/DuncanZauss/openpifpaf_assets/releases/download/v0.1.0/sk30_wholebody.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import openpifpaf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "openpifpaf.show.Canvas.show = True\n",
    "openpifpaf.show.Canvas.image_min_dpi = 200\n",
    "\n",
    "class Detector:\n",
    "    \"\"\"Given a still image (or video frame), finds poses.\n",
    "    \n",
    "    Attributes:  \n",
    "      device: PyTorch computing resource (GPU or CPU)  \n",
    "      net: Pose detection neural network model  \n",
    "      processor: Pose detection image processor  \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.device = torch.device('cuda')  # if cuda is available\n",
    "        except:\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "    def init_model(self, model_url=None, model_name=\"resnet50\", decoder=\"cifcaf\"):\n",
    "        #self.predictor = openpifpaf.Predictor(checkpoint='shufflenetv2k30-wholebody')\n",
    "        #self.predictor = openpifpaf.Predictor(checkpoint='shufflenetv2k30')\n",
    "        self.decoder = decoder # other decoder option=\"posesimilarity\"\n",
    "        self.predictor = openpifpaf.Predictor(checkpoint=model_name)\n",
    "\n",
    "    def detect_image(self, image_path, viz=False):\n",
    "        \"\"\" Applies the pose detection model to a single image file. Returns detections. \"\"\"\n",
    "        pil_im = PIL.Image.open(image_path)\n",
    "        image_array = np.asarray(pil_im)\n",
    "        \n",
    "        detections, gt_anns, image_meta = self.predictor.pil_image(pil_im)\n",
    "        \n",
    "        if viz:\n",
    "            self.plot_poses(detections, image_array, show=True)\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def __detect_pil_image__(self, pil_im):\n",
    "        detections, gt_anns, image_meta = self.predictor.pil_image(pil_im)\n",
    "        return detections\n",
    "        \n",
    "    \n",
    "    def plot_poses(self, detections, image_array=None, show=True, savepath=\"\", show_axis=False):\n",
    "\n",
    "        skeleton_painter = openpifpaf.show.painters.KeypointPainter()\n",
    "        # These are some of the viz parameters\n",
    "        #skeleton_painter = openpifpaf.show.painters.KeypointPainter(show_box=True, marker_size=1, line_width=6, highlight_invisible=True, show_joint_scales=True)\n",
    "        \n",
    "        # This is the most straightforward way to draw the skeletons and annotations, but\n",
    "        # it doesn't provide access to the viz parameters and doesn't allow the background\n",
    "        # to be blank\n",
    "        #annotation_painter = openpifpaf.show.AnnotationPainter()\n",
    "        #with openpifpaf.show.image_canvas(image_array) as ax:\n",
    "        #    annotation_painter.annotations(ax, detections) \n",
    "\n",
    "        vis_detections = []\n",
    "        \n",
    "        if hasattr(detections, 'data'):\n",
    "            vis_detections = [detections]\n",
    "        else:\n",
    "            for pose in detections:\n",
    "                if pose.data.shape[0] == 0:\n",
    "                    continue\n",
    "                vis_detections.append(pose)\n",
    "                \n",
    "        with openpifpaf.show.canvas() as ax:\n",
    "            if image_array is not None:\n",
    "                ax.imshow(image_array)\n",
    "            else:\n",
    "                # If there isn't a background image, the poses are plotted with the\n",
    "                # origin in the bottom left, rather than top left\n",
    "                ax.set_aspect('equal')\n",
    "                ax.invert_yaxis()\n",
    "            for detection in vis_detections:\n",
    "                skeleton_painter.annotation(ax, detection)\n",
    "            if not show_axis:\n",
    "                ax.set_axis_off()\n",
    "            fig = ax.get_figure()\n",
    "            fig.set_constrained_layout(True)\n",
    "            \n",
    "            if savepath != \"\":\n",
    "                fig.savefig(savepath)\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    def overlay_poses(self, image_array, figures_frame, show=False, source_figure='figures', show_axis=False, savepath=\"\"):\n",
    "        return self.plot_poses(figures_frame[source_figure], image_array, show=show, show_axis=show_axis, savepath=savepath)\n",
    "    \n",
    "    \n",
    "    def detect_video(self, video_file, start_seconds=0.0, end_seconds=0.0, max_frames=0, seconds_to_skip=0.0, images_too=False, write_images=False, output_images_path='video_folder'):\n",
    "        \"\"\" Given a video file, extracts video frames as images at `seconds_to_skip` intervals,\n",
    "            from `start_seconds` to `end_seconds`, and runs `__detect_one_or_more_images__()` on each.\n",
    "            Returns a list of frame pose data items, which are dictionaries with the following elements:\n",
    "            { 'frame_id': <the frame's position in this list (not in the entire video, if seconds_to_skip != 0)>, \n",
    "              'time': <the frame's timecode within the excerpt (not within the full video, if start_seconds != 0)>,\n",
    "              'figures': [<OpenPifPaf pose detection objects> for all figures detected in the frame]\n",
    "              <OPTIONAL> 'image': <a PIL image object for the frame>\n",
    "            }\n",
    "            `write_images`, if true, causes the extracted frame images to be written to a folder\n",
    "            specified by `output_images_path`, with the naming scheme `image00001.png`\n",
    "        \"\"\"\n",
    "        \n",
    "        GC_INTERVAL = 1000\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print('total frames in video:',total_frames)\n",
    "\n",
    "        video_framerate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        print('video FPS:',video_framerate)\n",
    "        frame_duration = 1 / float(video_framerate)\n",
    "\n",
    "        frame_count = 0.0\n",
    "        frames_processed = 0\n",
    "        timecode = 0.0\n",
    "        skip_until = start_seconds\n",
    "\n",
    "        pose_output = []\n",
    "\n",
    "        if write_images:\n",
    "            if not os.path.isdir(output_images_path):\n",
    "                os.mkdir(output_images_path)\n",
    "            for filename in os.listdir(output_images_path):\n",
    "                file_path = os.path.join(output_images_path, filename)\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "\n",
    "        bar = display(self.__progress__(0, total_frames-1), display_id=True)\n",
    "        while cap.isOpened() and (frame_count < total_frames):\n",
    "            ret_val, im = cap.read()\n",
    "\n",
    "            timecode = frame_count * frame_duration\n",
    "            frame_count += 1\n",
    "\n",
    "            bar.update(self.__progress__(frame_count, total_frames-1))\n",
    "\n",
    "            if (end_seconds and timecode > end_seconds) or (max_frames and frames_processed >= max_frames):\n",
    "                return pose_output\n",
    "\n",
    "            if timecode < start_seconds:\n",
    "                continue\n",
    "\n",
    "            if im is None:\n",
    "                # Might want to retry here\n",
    "                # print(\"Missed a frame, continuing...\")\n",
    "                # For now, we'll count a missed frame as a processed frame\n",
    "                continue\n",
    "\n",
    "            if seconds_to_skip and timecode < skip_until:\n",
    "                continue\n",
    "            else:\n",
    "                skip_until += seconds_to_skip\n",
    "\n",
    "            im_height, im_width, im_channels = im.shape\n",
    "\n",
    "            frame_id = int(round(cap.get(1)))\n",
    "\n",
    "            # Image doesn't necessarily come in as RGB(A)!\n",
    "            rgbim = cv2.cvtColor(im, cv2.COLOR_BGR2RGBA)\n",
    "            pil_image = PIL.Image.fromarray(rgbim)\n",
    "\n",
    "            detections = self.__detect_pil_image__(pil_image)\n",
    "\n",
    "            print(\"Frame\",frame_count,\"of\",total_frames,round(timecode,2),\"figures\",len(detections))\n",
    "\n",
    "            this_frame_data = {'frame_id': frame_count, 'time': timecode, 'figures': detections} #, 'flipped_figures': flipped_detections, 'zeroified_figures': zeroified_detections}\n",
    "            if images_too:\n",
    "                this_frame_data['image'] = rgbim\n",
    "            if write_images:\n",
    "                savepath = os.path.join(output_images_path, 'image' + str(int(frames_processed + 1)).zfill(5) + '.png')\n",
    "                self.overlay_poses(im, this_frame_data, source_figure='figures', savepath=savepath)\n",
    "                del im, rgbim, pil_image\n",
    "\n",
    "            pose_output.append(this_frame_data)\n",
    "            frames_processed += 1\n",
    "\n",
    "        return pose_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teddy = Detector()\n",
    "#detections = teddy.detect_image('sample_data/sample1.png', viz=True)\n",
    "#pose_output = teddy.detect_video(\"/srv/choreo/Einstein.mp4\", start_seconds=6310, end_seconds=7288, write_images=True, images_too=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teddy.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 25\n",
    "!ffmpeg -y -framerate $FPS -pattern_type glob -i 'video_folder/*.png' -strict '-2' -c:v libx264 -vf \"fps=$FPS\" -pix_fmt yuv420p Einstein_ballet_pf.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    teddy = Detector()\n",
    "    detections = teddy.detect_image('sample_data/sample1.png')\n",
    "    print(detections[0])\n",
    "except:\n",
    "    print(\"Unable to instantiate a detector on your system. Do you have PyTorch with CUDA enabled?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
